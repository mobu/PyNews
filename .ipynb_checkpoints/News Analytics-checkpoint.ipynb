{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import html\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn Summary \n",
      "\n",
      "   Polarity  Subjectivity TopWord  TopWordFreq  TotalWord\n",
      "0 -0.055556      0.544444   biden          4.0      140.0\n",
      "1 -0.004959      0.335093    hart         35.0     2387.0\n"
     ]
    }
   ],
   "source": [
    "source = 'cnn'\n",
    "date = '20180425'\n",
    "filename = 'gun control/CNN/{}Summary.csv'.format(date)\n",
    "\n",
    "df = pd.read_json(('gun control/CNN/gun-{}{}.json').format(source,date),encoding='utf-8',orient='columns')\n",
    "polarity = []\n",
    "subjectivity = []\n",
    "top_word = []\n",
    "wordlist = np.array([])\n",
    "ratio = np.array([])\n",
    "word_count = np.array([])\n",
    "sen_polarity = []\n",
    "sentence_array = []\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for k in df['Content'].iteritems():\n",
    "    analysis = TextBlob(str(k))\n",
    "    polarity.append(analysis.sentiment.polarity)\n",
    "    subjectivity.append(analysis.sentiment.subjectivity)\n",
    "    word_count = np.append(word_count,len(analysis.words))\n",
    "    \n",
    "    words = analysis.words\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "    words = [word for word in words if not word.isnumeric()]\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    fdist = nltk.FreqDist(words)\n",
    "    \n",
    "    for word, frequency in fdist.most_common(1):\n",
    "        wordlist = np.append(wordlist,frequency)\n",
    "        top_word.append(word)\n",
    "        \n",
    "data = pd.DataFrame({'Polarity': polarity,'Subjectivity': subjectivity,'TopWord':top_word,'TopWordFreq':wordlist,'TotalWord':word_count})\n",
    "\n",
    "print('{} Summary \\n'.format(source))\n",
    "data.sort_index(axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
